# -*- coding: utf-8 -*-
"""mnist_knn_linear_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JJ2saJDJamU9MephxIJwg7yJBkB9aw1f
"""

!pip install --upgrade numba umap-learn

pip install "numba==0.60.0"

import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets, decomposition, manifold, model_selection, neighbors, linear_model
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import umap
from google.colab import drive

# Montar Google Drive
drive.mount('/content/drive')
drive_folder = '/content/drive/MyDrive/colab_results'
os.makedirs(drive_folder, exist_ok=True)

# Carregar MNIST
mnist = datasets.fetch_openml('mnist_784', version=1)
X = mnist.data / 255.0
y = mnist.target.astype(int)

# Amostragem para execução rápida
X_small, _, y_small, _ = model_selection.train_test_split(X, y, train_size=10000, stratify=y, random_state=42)

# Técnicas de redução de dimensionalidade
def get_dimensionality_methods(X):
    return {
        'PCA': decomposition.PCA(n_components=50).fit_transform(X),
        't-SNE': manifold.TSNE(n_components=2, random_state=42).fit_transform(X),
        'UMAP': umap.UMAP(n_components=2, random_state=42).fit_transform(X),
    }

# Modelos
def get_models(distance_metric=None):
    models = {'Linear': linear_model.LogisticRegression(max_iter=1000)}
    if distance_metric:
        models[f'kNN ({distance_metric})'] = neighbors.KNeighborsClassifier(n_neighbors=3, metric=distance_metric)
    return models

# Proporções de divisão
split_ratios = [
    (0.8, 0.1, 0.1),
    (0.7, 0.15, 0.15),
    (0.6, 0.2, 0.2),
    (0.6, 0.3, 0.1),
    (0.5, 0.25, 0.25),
    (0.4, 0.3, 0.3),
]

# Distâncias para kNN
distance_metrics = ['euclidean', 'manhattan', 'chebyshev']

# Resultados
results = []

for dim_name, X_reduced in get_dimensionality_methods(X_small).items():
    for train_size, val_size, test_size in split_ratios:
        # Divisão inicial
        X_train_val, X_test, y_train_val, y_test = model_selection.train_test_split(
            X_reduced, y_small, test_size=test_size, stratify=y_small, random_state=42
        )
        val_relative = val_size / (train_size + val_size)
        X_train, X_val, y_train, y_val = model_selection.train_test_split(
            X_train_val, y_train_val, test_size=val_relative, stratify=y_train_val, random_state=42
        )

        # Avaliação modelos lineares
        for model_name, model in get_models().items():
            start_time = time.time()
            scores = model_selection.cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
            elapsed = time.time() - start_time

            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            results.append({
                'Dimensionality': dim_name,
                'Model': model_name,
                'Split': f"{int(train_size*100)}/{int(val_size*100)}/{int(test_size*100)}",
                'Distance': 'N/A',
                'Accuracy Mean': np.mean(scores),
                'Accuracy Std': np.std(scores),
                'Time (s)': elapsed
            })

        # Avaliação kNN com métricas de distância
        for metric in distance_metrics:
            for model_name, model in get_models(distance_metric=metric).items():
                start_time = time.time()
                scores = model_selection.cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
                elapsed = time.time() - start_time

                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)

                results.append({
                    'Dimensionality': dim_name,
                    'Model': 'kNN',
                    'Split': f"{int(train_size*100)}/{int(val_size*100)}/{int(test_size*100)}",
                    'Distance': metric,
                    'Accuracy Mean': np.mean(scores),
                    'Accuracy Std': np.std(scores),
                    'Time (s)': elapsed
                })

results_df = pd.DataFrame(results)
results_df['Accuracy %'] = results_df['Accuracy Mean'] * 100
# --- exportar resultados para CSV ---
csv_path = os.path.join(drive_folder, 'results_mnist.csv')  # mesmo Google Drive usado acima
results_df.to_csv(csv_path, index=False)
print(f'Resultados salvos em: {csv_path}')

plt.figure(figsize=(12, 6))
sns.barplot(data=results_df, x='Dimensionality', y='Accuracy %', hue='Model')
plt.title('Acurácia por Técnica de Redução e Modelo')
plt.ylim(80, 100)
plt.tight_layout()
plt.savefig(os.path.join(drive_folder, 'barplot_modelos_dimensionalidade.png'), dpi=300)
plt.show()

knn_df = results_df[results_df['Model'] == 'kNN'].copy()

for dim in knn_df['Dimensionality'].unique():
    subset = knn_df[knn_df['Dimensionality'] == dim]

    pivot = subset.pivot_table(index='Split', columns='Distance', values='Accuracy %')

    plt.figure(figsize=(8, 6))
    sns.heatmap(pivot, annot=True, fmt=".2f", cmap='Blues', cbar_kws={'label': 'Acurácia (%)'})
    plt.title(f'Heatmap de Acurácia (kNN) - {dim}')
    plt.xlabel('Métrica de Distância')
    plt.ylabel('Proporção de Divisão')
    plt.tight_layout()
    filename = f'heatmap_knn_accuracy_{dim}.png'
    plt.savefig(os.path.join(drive_folder, filename), dpi=300)
    plt.show()

plt.figure(figsize=(12, 6))
sns.boxplot(data=results_df, x='Model', y='Accuracy %', hue='Dimensionality')
plt.title('Distribuição da Acurácia por Modelo e Redução')
plt.tight_layout()
plt.savefig(os.path.join(drive_folder, 'boxplot_modelos_dimensionalidade.png'), dpi=300)
plt.show()

plt.figure(figsize=(10, 6))
sns.scatterplot(data=results_df, x="Time (s)", y="Accuracy Mean", hue="Model", style="Dimensionality", s=100)
plt.title("Dispersão: Acurácia vs Tempo de Execução")
plt.xlabel("Tempo de Execução (s)")
plt.ylabel("Acurácia Média")
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.savefig(os.path.join(drive_folder, 'scatter_accuracy_vs_time.png'), dpi=300)
plt.show()

top10 = results_df.sort_values("Accuracy Mean", ascending=False).head(10)
plt.figure(figsize=(12, 6))
sns.barplot(data=top10, x="Accuracy Mean", y="Model", hue="Dimensionality")
plt.title("Top 10 Configurações com Maior Acurácia")
plt.xlabel("Acurácia Média")
plt.ylabel("Modelo")
plt.tight_layout()
plt.savefig(os.path.join(drive_folder, 'top10_model_configurations.png'), dpi=300)
plt.show()

pivot_std = results_df.pivot_table(index="Dimensionality", columns="Model", values="Accuracy Std", aggfunc="mean")
plt.figure(figsize=(8, 6))
sns.heatmap(pivot_std, annot=True, fmt=".4f", cmap="YlGnBu")
plt.title("Desvio Padrão da Acurácia Média por Modelo e Técnica")
plt.xlabel("Modelo")
plt.ylabel("Técnica de Redução de Dimensionalidade")
plt.tight_layout()
plt.savefig(os.path.join(drive_folder, 'heatmap_accuracy_std.png'), dpi=300)
plt.show()

plt.figure(figsize=(8, 6))
sns.barplot(data=results_df, x="Model", y="Accuracy Mean", ci="sd", capsize=0.2)
plt.title("Acurácia Média por Modelo (todas as técnicas)")
plt.xlabel("Modelo")
plt.ylabel("Acurácia Média")
plt.tight_layout()
plt.savefig(os.path.join(drive_folder, 'accuracy_by_model.png'), dpi=300)
plt.show()